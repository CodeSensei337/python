{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnIXFT3hbQhz",
        "outputId": "c3c5439e-7c49-407a-c7ab-f69d920f62c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Setting up google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u528q8RCbQh6",
        "origin_pos": 0
      },
      "source": [
        "# Data Manipulation\n",
        "\n",
        "* Basic data structure used in Deep Learning is the $n$-dimensional array, which is also called the *tensor*.\n",
        "* *Tensor class* is called `Tensor` in PyTorch and is similar to NumPy's `ndarray` with a few killer features.\n",
        "    * First, GPU is well-supported to accelerate the computation\n",
        "    * Second, the tensor class supports automatic differentiation.\n",
        "* These properties make the tensor class suitable for Deep Learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKSF3PUXbQh7",
        "origin_pos": 5,
        "scrolled": true,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "# To start, we import `torch`. Note that it's called PyTorch, we should import `torch` instead of `pytorch`.\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dRE9OyLbQh8",
        "outputId": "2861d145-1c40-4f22-e16a-c4745af50ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGvyZmEwbQh9",
        "origin_pos": 7
      },
      "source": [
        "# Tensor\n",
        "\n",
        "* A tensor represents a (possibly multi-dimensional) array of numerical values.\n",
        "    * A 1D tensor corresponds (in math) to a *vector*.\n",
        "    * A 2D tensor corresponds to a *matrix*.\n",
        "    * Tensors with more than two axes do not have special mathematical names.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy1peA3MbQh9"
      },
      "source": [
        "# Vector\n",
        "\n",
        "* In math notation, we will usually denote vectors as bold-faced, lower-cased letters (e.g., $\\mathbf{x}$, $\\mathbf{y}$, and $\\mathbf{z})$.\n",
        "* Column vectors is the default orientation of vectors. In math, a column vector $\\mathbf{x}$ can be written as\n",
        "\n",
        "$$\\mathbf{x} =\\begin{bmatrix}x_{1}  \\\\x_{2}  \\\\ \\vdots  \\\\x_{n}\\end{bmatrix},$$\n",
        "where $x_1, \\ldots, x_n$ are elements of the vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxAdxaKcbQh9",
        "origin_pos": 9,
        "outputId": "89c7e078-3829-4629-c490-814ddaa1bec9",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([0, 1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "# A vector with 4 elements in the range 0-3\n",
        "# Unless otherwise specified, a new tensor is stored in main memory and designated for CPU-based computation\n",
        "x = torch.arange(4)\n",
        "print(type(x))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeQa40RabQh-",
        "outputId": "da21206b-35f8-4ad1-fa51-296f925b7ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3)\n"
          ]
        }
      ],
      "source": [
        "# access the i-th element: x[i]\n",
        "print(x[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI2FuIqebQh-",
        "origin_pos": 11,
        "outputId": "ee0a9a24-b447-4959-ff0f-0564d1869e7d",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 torch.Size([4]) torch.Size([4]) <class 'torch.Size'>\n"
          ]
        }
      ],
      "source": [
        "# Vector shape i.e. dimensionality \n",
        "print(len(x), x.size(), x.shape, type(x.size()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUb8DVCUbQh_"
      },
      "source": [
        "# Matrices\n",
        "\n",
        "* Matrices (i.e. 2D tensors) will be typically denoted with bold-faced, capital letters (e.g., $\\mathbf{X}$, $\\mathbf{Y}$, and $\\mathbf{Z}$).\n",
        "\n",
        "* In math notation, we use $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ to express that the matrix $\\mathbf{A}$ consists of $m$ rows and $n$ columns of real-valued scalars.\n",
        "\n",
        "* Visually, we can illustrate any matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ as a table,\n",
        "where each element $a_{ij}$ belongs to the $i^{\\mathrm{th}}$ row and $j^{\\mathrm{th}}$ column:\n",
        "\n",
        "$$\\mathbf{A}=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix}.$$\n",
        "\n",
        "* For any $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, the shape of $\\mathbf{A}$ is ($m$, $n$) or $m \\times n$.\n",
        "    * When a matrix has the same number of rows and columns, it is called a *square matrix*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U9keq5sbQh_",
        "outputId": "59a42ac0-5a08-4b7e-ab39-14ccbc4a3311",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11],\n",
              "         [12, 13, 14, 15],\n",
              "         [16, 17, 18, 19]]), tensor(11), tensor(11))"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reshape function: change the shape of a tensor without changing the number of elements or their values \n",
        "A = torch.arange(20).reshape(5, 4)\n",
        "A, A[2, 3], A[2][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMIwWi0ZbQh_",
        "outputId": "638bf951-9d93-40a0-dfb9-fb385ef94ed9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 torch.Size([5, 4]) torch.Size([5, 4])\n"
          ]
        }
      ],
      "source": [
        "# Matrix shape\n",
        "print(len(A), A.size(), A.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfnqT2DJbQiA",
        "outputId": "087063fa-e83d-45db-e49b-5799ca5d50c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use -1 for the dimension that can be automatically inferred\n",
        "A1 = torch.arange(20).reshape(5, -1);\n",
        "A2 = torch.arange(20).reshape(-1, 4);\n",
        "A==A1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq8STO4VbQiA",
        "outputId": "2f89dfce-661c-4fd1-e164-6dfef21be2e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0,  4,  8, 12, 16],\n",
              "         [ 1,  5,  9, 13, 17],\n",
              "         [ 2,  6, 10, 14, 18],\n",
              "         [ 3,  7, 11, 15, 19]]), tensor([[ 0,  4,  8, 12, 16],\n",
              "         [ 1,  5,  9, 13, 17],\n",
              "         [ 2,  6, 10, 14, 18],\n",
              "         [ 3,  7, 11, 15, 19]]))"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transpose\n",
        "B = A.T\n",
        "B1 = A.transpose(1, 0)\n",
        "B, B1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S2vzvhybQiB"
      },
      "source": [
        "# Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBVTYkptbQiB",
        "outputId": "c3189462-0df2-4f92-8a4d-ad4892c4536f",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# A 3D tensor\n",
        "X = torch.arange(24).reshape(2, 3, -1)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGz3gmpXbQiB"
      },
      "source": [
        "# Commonly-used Tensor Constuctors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dhFpD5sbQiB",
        "outputId": "e9e82f6b-839e-4759-eace-afeedb89e8be",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]])"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.ones((2, 3, 4)) # with Ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEi7T-_qbQiC",
        "outputId": "2864536a-4075-4f02-f2e6-df0192e6d5ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.zeros(2, 3) # with Zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tof2tVtGbQiC",
        "outputId": "c518c5b4-5e90-40ba-c89e-6036aac12d04",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1048, -0.4926, -0.5236, -0.9925],\n",
              "        [ 0.9997, -0.3656, -1.4240,  0.1609],\n",
              "        [ 0.7900, -0.9788,  2.1395,  0.9936]])"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.randn(3, 4) # samples from a Gaussian distribution with mean 0 and std of 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUy5p6A6bQiC",
        "outputId": "6f6b26c4-18ec-4b21-8fdc-ab0366795c74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 1, 4, 3],\n",
              "        [1, 2, 3, 4]])"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4]]) # From Python lists "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFZreKf2bQiD"
      },
      "source": [
        "# Common Tensor Operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp_a4tGObQiD",
        "outputId": "67845a13-004c-4caa-d52f-67011ea84c35",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]), tensor([[ 0.,  2.,  4.,  6.],\n",
              "         [ 8., 10., 12., 14.],\n",
              "         [16., 18., 20., 22.],\n",
              "         [24., 26., 28., 30.],\n",
              "         [32., 34., 36., 38.]]), tensor([[  0.,   1.,   4.,   9.],\n",
              "         [ 16.,  25.,  36.,  49.],\n",
              "         [ 64.,  81., 100., 121.],\n",
              "         [144., 169., 196., 225.],\n",
              "         [256., 289., 324., 361.]]), tensor([[ 2.,  3.,  4.,  5.],\n",
              "         [ 6.,  7.,  8.,  9.],\n",
              "         [10., 11., 12., 13.],\n",
              "         [14., 15., 16., 17.],\n",
              "         [18., 19., 20., 21.]]))"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
        "B = A.clone()  # Assign a copy of `A` to `B` by allocating new memory\n",
        "A, A + B, A * B, A + 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_8TN5WKbQiD",
        "outputId": "27026c09-a829-4d78-e410-58251280ab67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(190.), tensor([40., 45., 50., 55.]), tensor([ 6., 22., 38., 54., 70.]))"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summations (same applies for mean() function)\n",
        "A.sum(), A.sum(dim=0), A.sum(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9aakDknbQiE",
        "outputId": "0330bcdb-a5f0-4c83-c2d7-a1c32ef6b2cb",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01],\n",
              "         [5.4598e+01, 1.4841e+02, 4.0343e+02, 1.0966e+03],\n",
              "         [2.9810e+03, 8.1031e+03, 2.2026e+04, 5.9874e+04],\n",
              "         [1.6275e+05, 4.4241e+05, 1.2026e+06, 3.2690e+06],\n",
              "         [8.8861e+06, 2.4155e+07, 6.5660e+07, 1.7848e+08]]),\n",
              " tensor([[  0.,   1.,   4.,   9.],\n",
              "         [ 16.,  25.,  36.,  49.],\n",
              "         [ 64.,  81., 100., 121.],\n",
              "         [144., 169., 196., 225.],\n",
              "         [256., 289., 324., 361.]]),\n",
              " tensor([[  0.,   1.,   4.,   9.],\n",
              "         [ 16.,  25.,  36.,  49.],\n",
              "         [ 64.,  81., 100., 121.],\n",
              "         [144., 169., 196., 225.],\n",
              "         [256., 289., 324., 361.]]),\n",
              " tensor([[ 1.0000,  0.5403, -0.4161, -0.9900],\n",
              "         [-0.6536,  0.2837,  0.9602,  0.7539],\n",
              "         [-0.1455, -0.9111, -0.8391,  0.0044],\n",
              "         [ 0.8439,  0.9074,  0.1367, -0.7597],\n",
              "         [-0.9577, -0.2752,  0.6603,  0.9887]]))"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Functions are applied element-wise\n",
        "torch.exp(A), A**2, torch.pow(A, 2), torch.cos(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFwrFy6YbQiE",
        "outputId": "b73d5b44-d491-4776-fa40-64cc1d763cb1",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.],\n",
              "         [ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]),\n",
              " tensor([[ 0.,  1.,  2.,  3.,  0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.,  4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.,  8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15., 12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19., 16., 17., 18., 19.]]))"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concatenation\n",
        "torch.cat((A, B), dim=0), torch.cat((A, B), dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQvDz7TqbQiE"
      },
      "source": [
        "# Dot Products\n",
        "\n",
        "* One of the most fundamental operations. \n",
        "* Given two vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d$, their *dot product* $\\mathbf{x}^\\top \\mathbf{y}$ (or $\\langle \\mathbf{x}, \\mathbf{y}  \\rangle$) is a sum over the products of the elements at the same position: $\\mathbf{x}^\\top \\mathbf{y} = \\sum_{i=1}^{d} x_i y_i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VMPW6RmbQiE",
        "outputId": "7a392b67-dbae-4e50-a36c-3507646c8609"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(4, dtype=torch.float32)\n",
        "y = torch.ones(4, dtype = torch.float32)\n",
        "x, y, torch.dot(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlrjbcofbQiF"
      },
      "source": [
        "* Dot products are useful in a wide range of contexts:\n",
        "    1. Given features stored in vector $\\mathbf{x}  \\in \\mathbb{R}^d$ and model weights in vector $\\mathbf{w} \\in \\mathbb{R}^d$, the *score* between features and model weights are given by $\\mathbf{x}^\\top \\mathbf{w}$.\n",
        "    2. When the weights are non-negative and sum to one (i.e., $\\left(\\sum_{i=1}^{d} {w_i} = 1\\right)$), the dot product expresses a *weighted average*.\n",
        "    3. After normalizing two vectors to have the unit length (to be defined below), the dot products express the cosine of the angle between them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWkx1OVQbQiF"
      },
      "source": [
        "# Matrix-Vector Products\n",
        "\n",
        "* Recall $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ and $\\mathbf{x} \\in \\mathbb{R}^n$. Let us write $\\mathbf{A}$ in terms of its row vectors:\n",
        "$$\\mathbf{A}=\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\\\\n",
        "\\mathbf{a}^\\top_{2} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{a}^\\top_m \\\\\n",
        "\\end{bmatrix},$$\n",
        "where each $\\mathbf{a}^\\top_{i} \\in \\mathbb{R}^n$ is a row vector representing the $i^\\mathrm{th}$ row of the matrix $\\mathbf{A}$.\n",
        "\n",
        "* $\\mathbf{A}\\mathbf{x}$ is a column vector of length $m$, whose $i^\\mathrm{th}$ element is $\\mathbf{a}^\\top_i \\mathbf{x}$:\n",
        "\n",
        "$$\n",
        "\\mathbf{A}\\mathbf{x}\n",
        "= \\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\\\\n",
        "\\mathbf{a}^\\top_{2} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{a}^\\top_m \\\\\n",
        "\\end{bmatrix}\\mathbf{x}\n",
        "= \\begin{bmatrix}\n",
        " \\mathbf{a}^\\top_{1} \\mathbf{x}  \\\\\n",
        " \\mathbf{a}^\\top_{2} \\mathbf{x} \\\\\n",
        "\\vdots\\\\\n",
        " \\mathbf{a}^\\top_{m} \\mathbf{x}\\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "* Multiplication by $\\mathbf{A}\\in \\mathbb{R}^{m \\times n}$ projects vectors from $\\mathbb{R}^{n}$ to $\\mathbb{R}^{m}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlHXImeIbQiF",
        "outputId": "d88cd6cc-a8f2-44e1-8f72-bec8a287eb06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.shape, x.shape, torch.mv(A, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4WilX3FbQiF"
      },
      "source": [
        "# Matrix-Matrix Multiplication\n",
        "\n",
        "\n",
        "* Asssume that we have two matrices $\\mathbf{A} \\in \\mathbb{R}^{n \\times k}$ and $\\mathbf{B} \\in \\mathbb{R}^{k \\times m}$:\n",
        "\n",
        "$$\\mathbf{A}=\\begin{bmatrix}\n",
        " a_{11} & a_{12} & \\cdots & a_{1k} \\\\\n",
        " a_{21} & a_{22} & \\cdots & a_{2k} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        " a_{n1} & a_{n2} & \\cdots & a_{nk} \\\\\n",
        "\\end{bmatrix},\\quad\n",
        "\\mathbf{B}=\\begin{bmatrix}\n",
        " b_{11} & b_{12} & \\cdots & b_{1m} \\\\\n",
        " b_{21} & b_{22} & \\cdots & b_{2m} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        " b_{k1} & b_{k2} & \\cdots & b_{km} \\\\\n",
        "\\end{bmatrix}.$$\n",
        "\n",
        "\n",
        "* Denote by $\\mathbf{a}^\\top_{i} \\in \\mathbb{R}^k$ the row vector representing the $i^\\mathrm{th}$ row of $\\mathbf{A}$, and by $\\mathbf{b}_{j} \\in \\mathbb{R}^k$ the column vector from the $j^\\mathrm{th}$ column of $\\mathbf{B}$. We write $\\mathbf{A}$ and $\\mathbf{B}$ as:\n",
        "\n",
        "$$\\mathbf{A}=\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\\\\n",
        "\\mathbf{a}^\\top_{2} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{a}^\\top_n \\\\\n",
        "\\end{bmatrix},\n",
        "\\quad \\mathbf{B}=\\begin{bmatrix}\n",
        " \\mathbf{b}_{1} & \\mathbf{b}_{2} & \\cdots & \\mathbf{b}_{m} \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "* Then the matrix product $\\mathbf{C} \\in \\mathbb{R}^{n \\times m}$ is:\n",
        "\n",
        "$$\\mathbf{C} = \\mathbf{AB} = \\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\\\\n",
        "\\mathbf{a}^\\top_{2} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{a}^\\top_n \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        " \\mathbf{b}_{1} & \\mathbf{b}_{2} & \\cdots & \\mathbf{b}_{m} \\\\\n",
        "\\end{bmatrix}\n",
        "= \\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\mathbf{b}_1 & \\mathbf{a}^\\top_{1}\\mathbf{b}_2& \\cdots & \\mathbf{a}^\\top_{1} \\mathbf{b}_m \\\\\n",
        " \\mathbf{a}^\\top_{2}\\mathbf{b}_1 & \\mathbf{a}^\\top_{2} \\mathbf{b}_2 & \\cdots & \\mathbf{a}^\\top_{2} \\mathbf{b}_m \\\\\n",
        " \\vdots & \\vdots & \\ddots &\\vdots\\\\\n",
        "\\mathbf{a}^\\top_{n} \\mathbf{b}_1 & \\mathbf{a}^\\top_{n}\\mathbf{b}_2& \\cdots& \\mathbf{a}^\\top_{n} \\mathbf{b}_m\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yft9jH64bQiG",
        "outputId": "22592069-2dfb-4403-e6b2-d36711f57c51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]), tensor([[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]), tensor([[ 6.,  6.,  6.],\n",
              "         [22., 22., 22.],\n",
              "         [38., 38., 38.],\n",
              "         [54., 54., 54.],\n",
              "         [70., 70., 70.]]))"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication\n",
        "B = torch.ones(4, 3)\n",
        "A, B, torch.mm(A, B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1ewx1oBbQiH"
      },
      "source": [
        "# Norms\n",
        "\n",
        "* Some of the most useful operators in linear algebra are *norms*.\n",
        "* Informally, the norm of a vector tells us how *big* a vector is (0 is the minimum). \n",
        "* A (vector) norm is a function $f$ that maps a vector to a scalar, satisfying the following properties:\n",
        "    1. $f(\\alpha \\mathbf{x}) = |\\alpha| f(\\mathbf{x}).$\n",
        "\n",
        "    2. $f(\\mathbf{x} + \\mathbf{y}) \\leq f(\\mathbf{x}) + f(\\mathbf{y}).$\n",
        "\n",
        "    3. $f(\\mathbf{x}) \\geq 0.$\n",
        "\n",
        "    4. $\\forall i, x_i = 0 \\Leftrightarrow f(\\mathbf{x})=0.$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLvYSJkRbQiH"
      },
      "source": [
        "* The $L_2$ *norm* of $\\mathbf{x}$ is the square root of the sum of the squares of the vector elements:\n",
        "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2},$$\n",
        "where the subscript $2$ is often omitted in $L_2$ norms, i.e., $\\|\\mathbf{x}\\|$ is equivalent to $\\|\\mathbf{x}\\|_2$. \n",
        "\n",
        "* The $L_1$ *norm* is expressed as the sum of the absolute values of the vector elements:\n",
        "\n",
        "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|.$$\n",
        "\n",
        "* In Deep Learning, we are often trying to solve optimization problems: e.g. *minimize* the distance between the model's predictions and the ground-truth observations.\n",
        "    * The optimization obectives are ofter expressed as norms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUfy0xr5bQiH",
        "origin_pos": 53
      },
      "source": [
        "# Broadcasting Mechanism\n",
        "\n",
        "* In maths, in order to to perform elementwise operations between two tensors, they need to have the same shape. \n",
        "* In Python and PyTorch, under certain conditions, even when their shapes differ, we can still perform elementwise operations by invoking the *broadcasting mechanism*.\n",
        "* This mechanism works in the following way: \n",
        "    * First, expand one or both arrays by copying elements appropriately so that after this transformation, the two tensors have the same shape.\n",
        "    * Second, carry out the elementwise operations on the resulting arrays.\n",
        "\n",
        "* In most cases, we broadcast along a dimension where an array initially only has length 1, such as in the following example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI5nPGrnbQiH",
        "origin_pos": 55,
        "outputId": "d70c3915-e3d1-466f-86e9-570899559581",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0],\n",
              "         [1],\n",
              "         [2]]), tensor([[0, 1]]), torch.Size([3, 1]), torch.Size([1, 2]))"
            ]
          },
          "execution_count": 23,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.arange(3).reshape((3, 1))\n",
        "b = torch.arange(2).reshape((1, 2))\n",
        "a, b, a.size(), b.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF3rrJd9bQiI",
        "origin_pos": 58,
        "outputId": "6f9c68c3-02e3-4b30-8d8a-ef0ad3479bcb",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67G-yuhxbQiI"
      },
      "outputs": [],
      "source": [
        "# Another example with sums\n",
        "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoWThrfpbQiJ",
        "outputId": "74329979-3603-41af-dc99-2700f1632cf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 6., 22., 38., 54., 70.]), tensor([[ 6.],\n",
              "         [22.],\n",
              "         [38.],\n",
              "         [54.],\n",
              "         [70.]]))"
            ]
          },
          "execution_count": 26,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B1 = A.sum(dim=1);\n",
        "B2 = A.sum(dim=1, keepdims=True);\n",
        "B1, B2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf77hLrpbQiJ",
        "outputId": "34c2da53-e7ec-4efa-a536-f09abe94cf65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5]), torch.Size([5, 1]))"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimensionality\n",
        "B1.size(), B2.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BobOi9e3bQiK",
        "outputId": "d04a1865-0f75-4baf-fc03-920bb0352b69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
              "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
              "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
              "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
              "        [0.2286, 0.2429, 0.2571, 0.2714]])"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A/B2 # A/B1 won't work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFP1LNMDbQiK",
        "origin_pos": 59
      },
      "source": [
        "# Tensor Indexing and Slicing\n",
        "\n",
        "* Just as in any other Python array, elements in a tensor can be accessed by index.\n",
        "    * The first element has index 0 and ranges are specified to include the first but *before* the last element.\n",
        "    * As in standard Python lists, we can access elements according to their relative position to the end of the list by using negative indices.\n",
        "    * Example: `[-1]` selects the last element and `[1:3]` selects the second and the third elements as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvD7dGIrbQiL",
        "origin_pos": 60,
        "outputId": "fab1c1d7-14b0-4c48-d8f8-70e00c06afee",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]), tensor([[ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.]]), tensor([[4., 5.],\n",
              "         [8., 9.]]), tensor([16., 17., 18., 19.]), tensor([[12., 13., 14., 15.]]))"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
        "X, X[1:3, :], X[1:3, :2],  X[-1, :], X[-2:-1, :] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1ua9S-KbQiL",
        "origin_pos": 68
      },
      "source": [
        "# Saving Memory\n",
        "\n",
        "* Running operations can cause new memory to be allocated to store the results.\n",
        "* We do not want to allocate memory unnecessarily all the time.\n",
        "    * In machine learning, we might have hundreds of megabytes of parameters\n",
        "* Where possible, we want to perform these updates *in place*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5HAGjd9bQiL",
        "origin_pos": 69,
        "outputId": "2fa8888c-3312-4661-dc26-bd5cc9164b14",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "140377999456584 140377999456512\n",
            "140377999456584 140377999432944\n",
            "140377999456584 140377999432944\n",
            "140377999456584 140377999432944\n"
          ]
        }
      ],
      "source": [
        "# In place example\n",
        "X = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
        "Y = 10*X\n",
        "print(id(X), id(Y))\n",
        "Y = Y + X # not in-place\n",
        "print(id(X), id(Y))\n",
        "Y += X # in-place\n",
        "print(id(X), id(Y))\n",
        "Y[:] = Y + X # in-place\n",
        "print(id(X), id(Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPZ7SUmybQiM",
        "origin_pos": 80
      },
      "source": [
        "# Conversion to Other Python Objects\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGMYuFTsbQiM",
        "origin_pos": 82,
        "outputId": "f3d79b90-ac32-421b-8cb6-09372635b590",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(numpy.ndarray, torch.Tensor)"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Converting to a NumPy array, or vice versa\n",
        "A = X.numpy()\n",
        "B = torch.tensor(A)\n",
        "type(A), type(B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdBl_j_AbQiM",
        "origin_pos": 86,
        "outputId": "dca06836-afd2-4a07-a134-994767860aec",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([3.5000]), 3.5, 3.5, 3)"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Converting to a size-1 tensor to a Python scalar,\n",
        "a = torch.tensor([3.5])\n",
        "a, a.item(), float(a), int(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xaA19TIxU8f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}