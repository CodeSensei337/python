{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMh/693UjBkz81cEu1mx3lf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center>**Principles of Machine Learning**</center>\n",
        "## <center>**Coursework 3 (advanced implementation)**</center>\n",
        "\n",
        "**Table of Contents**\n",
        "\n",
        "Declaration\n",
        "\n",
        "1. Section 1: Author\n",
        "\n",
        "2. Section 2: Problem Formulation\n",
        "  * Section 2.1: Outline\n",
        "  * Scetion 2.2: Sampling in Relation to Audio Files\n",
        "  * Section 2.3: Melody vs. Harmony: Similarities and Differences\n",
        "  * Section 2.4: Proposed Methodology\n",
        "\n",
        "3. Section 3: Machine Learning Pipeline\n",
        "  * Section 3.1: Loading the Data\n",
        "  * Section 3.2: Data Preparation\n",
        "\n",
        "4. Section 4: Transformation Stage \n",
        "  * Section 4.1: Feature Extraction\n",
        "\n",
        "5. Section 5: Modelling\n",
        "\n",
        "6. Section 6: Methodology\n",
        "  * Section 6.1: Model Fitting, Training and Validation\n",
        "  * Section 6.2: Testing\n",
        "    * Section 6.2.1: Class 1\n",
        "    * Section 6.2.2: Class 0\n",
        "\n",
        "7. Section 7: Dataset\n",
        "\n",
        "8. Section 8: Results\n",
        "\n",
        "9. Section 9: Conclusions"
      ],
      "metadata": {
        "id": "lfPD3Ydap6bF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Declaration:** Some of the code used in this assignment has been adapted and customized from www.docs.python.org/, www.matplotlib.org/stable/, www.pandas.pydata.org/docs, www.stackoverflow.com/questions/, www.geeksforgeeks.org/, www.kite.com/python/, www.codegrepper.com/, www.stats.stackexchange.com/questions/, www.machinelearningmind.com/, www.kaggle.com/, www.scikit-learn.org, www.towardsdatascience.com/, www.github.com/, www.librosa.org/blog/2019/07/17/resample-on-load/#resample-on-load/, www.librosa.org/doc/main/generated/librosa.feature.mfcc/, www.librosa.org/doc/main/generated/librosa.stft/, ML Foundations with Laurence Moroney at https://www.youtube.com/playlist?list=PLOU2XLYxmsII9mzQ-Xxug4l2o04JBrkLV, and Principles of Machine Learning Lab, Tutorial and Lecture Notes.<br> \n",
        "\n",
        "Non-coding information on \"melodies\" and \"harmonies\" is learned, surmised, summarised, and quoted from www.masterclass.com/articles/melody-vs-harmony-similarities-and-differences-with-musical-examples/, www.en.wikipedia.org/wiki/Melody/, and www.en.wikipedia.org/wiki/Harmony/."
      ],
      "metadata": {
        "id": "aC--N1udZ2v1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 1: Author**<br> \n",
        "**Student Name**: Kweku Esuon Acquaye<br> \n",
        "\n",
        "### **Section 2: Problem Formulation**<br> \n",
        "This report uses modern data science methods to analyse audio files from the MLEnd Hums and Whistles dataset, and to build a machine learning pipeline that takes as input an audio segment from the dataset and predicts its classification as either a melody or a harmony. It constitutes Coursework 3 in fulfilment of the requirements of Principles of Machine Learning module.<br> \n",
        "\n",
        "#### **Section 2.1: Outline**<br>\n",
        "The MLEndHW dataset consists of participant-submitted 15-second humming and whistling recordings of fragments of 8 different movie songs. Each participant submitted 2 humming and 2 whistling renditions per song (32 per participant), along with their demographic data. Demographic data is currently unavailable for this task.<br> \n",
        "\n",
        "With 210 participants there are 210 x 4 x 8 = 6720 audio files, anonymised with sample numbers, e.g. S12. The task in this notebook is to<br>\n",
        "1. understand data\n",
        "2. decide which data to extract and how to represent it\n",
        "3. inspect a few recordings for anything unexpected\n",
        "4. decide what can be automated and what needs to be done manually\n",
        "5. figure out how to automate what needs to be automated\n",
        "6. formulate a machine learning problem that can be attempted using the MLEndHW dataset and build a solution model."
      ],
      "metadata": {
        "id": "8QBhO8axDL24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Section 2.2: _Sampling_ in Relation to Audio Files**<br> \n",
        "An attempt at explaining the potentially confusing use of the term 'sample' in the field of audio processing is made herein as follows: Dataframe files are invariably reffered to in machine learning terms as 'samples', i.e. every row is a sample. However, audio files in themselves have a property referred to as 'sample', or more appropriately 'sample rate', which refers to the number of times the continuous sinusoidal sound wave is _accessed_ and _assessed_ (captured, recorded, snap-shot taken, digitally recorded, etc) in a series of discrete values. Basic information on this distinction is obtained from, among other sources, https://techterms.com/definition/sampling, https://techterms.com/definition/sample_rate, https://www.vocitec.com/docs-tools/blog/sampling-rates-sample-depths-and-bit-rates-basic-audio-concepts, https://en.wikipedia.org/wiki/Sampling_(signal_processing). Sampling rate (or sampling frequency) is measured in Hertz (Hz) which is the number of samples taken in 1 second.<br>  \n"
      ],
      "metadata": {
        "id": "dc6kbF2wjEp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Section 2.3: Melody vs. Harmony: Similarities and Differences**<br> \n",
        "Music has 3 primary elements: melody, harmony, and rhythm. Lyrics constitute a 4th element when there is singing. Melody and harmony, which work in tandem but are distinct from one another, are based on the arrangement of pitches.<br> \n",
        "\n",
        "A melody is a collection of musical tones that are grouped together as a single entity$^1$. Most compositions consist of multiple melodies working in conjunction with one another. A melody has 2 primary components - pitch and duration. Pitch is the actual audio vibration produced by an instrument, voice, hum, whistle or other expression of the music$^2$. It is basically the frequecy of the sound wave. Duration is the time that each pitch lasts and is divided into lengths of whole notes, half notes, quarter-note triplets, etc.<br> \n",
        "\n",
        "A harmony is the result of amalgamation of musical notes to form a cohesive whole$^3$. It is typically analysed as a series of chords. Harmonies are referred to as the vertical aspect of music as opposed to melodies which are referred to as horizontal$^4$. Although harmonies are simultaneously occurring frequencies, pitches, tones, notes, or chords, both melodic and harmonic outputs can be decomposed into consituent pitches, frequencies, power, and other properties of music. It is these properties that would be utilised to classify the dataset into melodies and harmonies."
      ],
      "metadata": {
        "id": "AwNloPF2JVOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Section 2.4: Proposed Methodology**<br> \n",
        "In this task the attempted methodology would be to divide the 8 songs of the dataset into melodic and harmonic classes. Each of these would then be divided 70% and 30%, the former for traing and the latter for testing. A pipeline to train a model consisting of a neural network would then be built that takes as input an audio segment of a hum and outputs a prediction of its melodic or harmonic class.<br> \n",
        "\n",
        "Due to the disparate acoustic properties of hums and whistles, it is decided to use hums only to obtain better model accuracy in this task. Hums from all 16 parts of the dataset would be combined into one dataset to train the model."
      ],
      "metadata": {
        "id": "rS7L6DaFbstN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 3: Machine Learning Pipeline**<br> \n",
        "The following steps constitute the machine learning pipeline built to achieve the purpose of this task:<br> \n",
        "\n",
        "#### **Section 3.1: Loading the Data**<br> \n",
        "The following steps import the necessary dependencies and mounts the drive (i.e. makes drive directly available to Colab) where original audio data files are stored."
      ],
      "metadata": {
        "id": "KAaNL0PCHkIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os, sys, re, pickle, glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from glob import glob\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "\n",
        "# Mounting Google Drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8ivMbqnJHff",
        "outputId": "a20e8a6a-4684-4571-d1ec-21702cc5385c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function is defined to download MLEndHW dataset files:"
      ],
      "metadata": {
        "id": "ttN7MeAxJVXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating function\n",
        "def download_url(url, save_path):\n",
        "    with urllib.request.urlopen(url) as dl_file:\n",
        "        with open(save_path, 'wb') as out_file:\n",
        "            out_file.write(dl_file.read())\n",
        "\n",
        "print(\"Zip download function created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQqwqBLbJOUP",
        "outputId": "9fa8f2f8-d007-4036-f194-50b9bf85e15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip download function created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Files of the MLEndHW dataset are found to be no longer available at the original location, hence a copy of the dataset made available on OneDrive and shared on the student forum by a colleague is downloaded to Google Drive.<br> \n",
        "\n",
        "The next step extracts the zipped zip files:"
      ],
      "metadata": {
        "id": "udaIvWTgLMWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting files at 1st level\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/Data.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "print(\"First level extraction completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg7qx0RSeSif",
        "outputId": "8099f981-8b46-4fb1-e7e3-31cae59b020c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First level extraction completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell checks the presence of extracted zip files:"
      ],
      "metadata": {
        "id": "8QqYgf9gT9oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listing files of 1st level extraction\n",
        "import os\n",
        "path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data'\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxFHh-a0iWiJ",
        "outputId": "6728850a-8e80-4e4c-f4ca-ff658c4bda43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Frozen_1.zip',\n",
              " 'Frozen_2.zip',\n",
              " 'Hakuna_1.zip',\n",
              " 'Hakuna_2.zip',\n",
              " 'Mamma_1.zip',\n",
              " 'Mamma_2.zip',\n",
              " 'Panther_1.zip',\n",
              " 'Panther_2.zip',\n",
              " 'Potter_1.zip',\n",
              " 'Potter_2.zip',\n",
              " 'Rain_1.zip',\n",
              " 'Rain_2.zip',\n",
              " 'Showman_1.zip',\n",
              " 'Showman_2.zip',\n",
              " 'StarWars_1.zip',\n",
              " 'StarWars_2.zip']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next few steps, audio files are extracted into named folders (there is reassignment of variable names):"
      ],
      "metadata": {
        "id": "aih2mQAHpMie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Panther1 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/panther1/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Panther_1.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/panther1/*.wav'\n",
        "files1 = glob(sample_path)\n",
        "print(\"There are\", len(files1), \"audio files in panther1 folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttpgd-I1Wcne",
        "outputId": "dff4ec3b-92fa-40b0-a014-ce39a2d19a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 208 audio files in panther1 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Panther2 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/panther2/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Panther_2.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/panther2/*.wav'\n",
        "files2 = glob(sample_path)\n",
        "print(\"There are\", len(files2), \"audio files in panther2 folder.\")"
      ],
      "metadata": {
        "id": "C7fkSa7yWch-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408da1cd-0c40-48d7-cb7c-9a681a56d70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 205 audio files in panther2 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Rain1 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/rain1/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Rain_1.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/rain1/*.wav'\n",
        "files3 = glob(sample_path)\n",
        "print(\"There are\", len(files3), \"audio files in rain1 folder.\")"
      ],
      "metadata": {
        "id": "yP252a02WcbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb7e3d30-efa1-48d5-d59a-4219d7beb412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 208 audio files in rain1 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Rain2 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/rain2/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Rain_2.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/rain2/*.wav'\n",
        "files4 = glob(sample_path)\n",
        "print(\"There are\", len(files4), \"audio files in rain2 folder.\")"
      ],
      "metadata": {
        "id": "b4DgwZdrWcU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866ed867-5f67-4bce-cdea-2baa60c6446e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 205 audio files in rain2 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Hakuna1 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/hakuna1/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Hakuna_1.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/hakuna1/*.wav'\n",
        "files5 = glob(sample_path)\n",
        "print(\"There are\", len(files5), \"audio files in hakuna1 folder.\")"
      ],
      "metadata": {
        "id": "OwgnPLuiWcO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109b9f6c-e25c-4de5-9159-f78ee50c54ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 213 audio files in hakuna1 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Hakuna2 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/hakuna2/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Hakuna_2.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/hakuna2/*.wav'\n",
        "files6 = glob(sample_path)\n",
        "print(\"There are\", len(files6), \"audio files in hakuna2 folder.\")"
      ],
      "metadata": {
        "id": "ee441B1zWcJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6648cd8-9eee-4c53-f1e8-3aefa761f13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 199 audio files in hakuna2 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Mamma1 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/mamma1/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Mamma_1.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/mamma1/*.wav'\n",
        "files7 = glob(sample_path)\n",
        "print(\"There are\", len(files7), \"audio files in mamma1 folder.\")"
      ],
      "metadata": {
        "id": "NKygGmz6WcDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f814fd2f-f50d-4b88-88c5-28779376c169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 217 audio files in mamma1 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Mamma2 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/mamma2/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Mamma_2.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/mamma2/*.wav'\n",
        "files8 = glob(sample_path)\n",
        "print(\"There are\", len(files8), \"audio files in mamma2 folder.\")"
      ],
      "metadata": {
        "id": "P8gD25rEWb92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504679c3-62f7-49ae-be82-8591a481ac5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 195 audio files in mamma2 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Showman1 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/showman1/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Showman_1.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/showman1/*.wav'\n",
        "files9 = glob(sample_path)\n",
        "print(\"There are\", len(files9), \"audio files in showman1 folder.\")"
      ],
      "metadata": {
        "id": "zFTOGOu6Wb42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599b7d85-046f-497d-bab3-888eca4ccd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 207 audio files in showman1 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Showman2 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/showman2/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Showman_2.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/showman2/*.wav'\n",
        "files10 = glob(sample_path)\n",
        "print(\"There are\", len(files10), \"audio files in showman2 folder.\")"
      ],
      "metadata": {
        "id": "DkScvGhlWbzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a807bf-084e-41b0-eb3b-45649ff6d1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 203 audio files in showman2 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Frozen1 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/frozen1/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Frozen_1.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/frozen1/*.wav'\n",
        "files11 = glob(sample_path)\n",
        "print(\"There are\", len(files11), \"audio files in frozen1 folder.\")"
      ],
      "metadata": {
        "id": "z4TvmugbWbf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf673776-0168-411a-b771-7d777502acd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 200 audio files in frozen1 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Frozen2 files\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/frozen2/'\n",
        "zip_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/Data/Frozen_2.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Counting files\n",
        "sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/all_samples/frozen2/*.wav'\n",
        "files12 = glob(sample_path)\n",
        "print(\"There are\", len(files12), \"audio files in frozen2 folder.\")"
      ],
      "metadata": {
        "id": "64ucQIcRWOUm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7211f486-aa04-4aaf-da9a-335b6b241311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 210 audio files in frozen2 folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Section 3.2: Data Preparation**\n",
        "\n",
        "To proceed further, a determination is made as to which tunes are melodies and which are harmonies. Using the original YouTube music tunes and the information summarised in Section 2.3 above, the following demacartion is made:<br> \n",
        "\n",
        "**Melodies** = Potter, Rain, Mamma, and Frozen.<br> \n",
        "**Harmonies** = StarWars, Panther, Hakuna, and Showman.<br> \n",
        "\n",
        "Although Mamma qualifies as both melody and harmony, it was judged to be marginally more melodic than harmonic and assigned as a melody.<br> \n",
        "\n",
        "All audio files, including preprocessed Potter and StaWars files from earlier basic implementation, are then manually transferred to one of two folders labbelled as \"melodies_train\" or \"harmonies_train\". A total of 76 files are determined to be unloadable due to errors in their formatting and deleted. 120 files from each folder are then transferred to corresponding \"melodies_test\" and \"harmonies_test\" folders.\n",
        "\n"
      ],
      "metadata": {
        "id": "r6T9OuQG-Pmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading melodies training and validation data\n",
        "melodies_sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/melodies_train/*.wav'\n",
        "files = glob(melodies_sample_path)\n",
        "len(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjtsJOQKCg9A",
        "outputId": "de69bee8-1878-414d-b8df-0400e4c5762a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1432"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting melodies info from filenames\n",
        "melody_table = [] \n",
        "\n",
        "for file in files:\n",
        "  try:\n",
        "    file_name = file.split('/')[-1]\n",
        "    participant_ID = file.split('/')[-1].split('_')[0]\n",
        "    interpretation_type = file.split('/')[-1].split('_')[1]\n",
        "    interpretation_number = file.split('/')[-1].split('_')[2]\n",
        "    song = file.split('/')[-1].split('_')[3].split('.')[0]\n",
        "    melody_table.append([file_name,participant_ID,interpretation_type,interpretation_number, song])\n",
        "  except:\n",
        "    print(file_name)\n",
        "    \n",
        "melody_table[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OjsCjCoDYmx",
        "outputId": "69333543-b229-4b60-e794-c87d326570cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['S73_hum_1_Rain.wav', 'S73', 'hum', '1', 'Rain'],\n",
              " ['S73_hum_4_Rain.wav', 'S73', 'hum', '4', 'Rain'],\n",
              " ['S74_hum_1_Rain.wav', 'S74', 'hum', '1', 'Rain'],\n",
              " ['S74_hum_4_Rain.wav', 'S74', 'hum', '4', 'Rain'],\n",
              " ['S75_hum_1_Rain.wav', 'S75', 'hum', '1', 'Rain']]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating melodies dataframe of training files\n",
        "melody_df = pd.DataFrame(melody_table,columns=['file_id','participant','interpretation','number','song']).set_index('file_id') \n",
        "melody_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "DzUKbWszDnni",
        "outputId": "5a134f62-80d7-4b51-e7ce-f67aba675dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7342893f-8764-4568-9f08-be2fe474a1f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant</th>\n",
              "      <th>interpretation</th>\n",
              "      <th>number</th>\n",
              "      <th>song</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>file_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>S73_hum_1_Rain.wav</th>\n",
              "      <td>S73</td>\n",
              "      <td>hum</td>\n",
              "      <td>1</td>\n",
              "      <td>Rain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S73_hum_4_Rain.wav</th>\n",
              "      <td>S73</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Rain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S74_hum_1_Rain.wav</th>\n",
              "      <td>S74</td>\n",
              "      <td>hum</td>\n",
              "      <td>1</td>\n",
              "      <td>Rain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S74_hum_4_Rain.wav</th>\n",
              "      <td>S74</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Rain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S75_hum_1_Rain.wav</th>\n",
              "      <td>S75</td>\n",
              "      <td>hum</td>\n",
              "      <td>1</td>\n",
              "      <td>Rain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7342893f-8764-4568-9f08-be2fe474a1f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7342893f-8764-4568-9f08-be2fe474a1f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7342893f-8764-4568-9f08-be2fe474a1f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   participant interpretation number  song\n",
              "file_id                                                   \n",
              "S73_hum_1_Rain.wav         S73            hum      1  Rain\n",
              "S73_hum_4_Rain.wav         S73            hum      4  Rain\n",
              "S74_hum_1_Rain.wav         S74            hum      1  Rain\n",
              "S74_hum_4_Rain.wav         S74            hum      4  Rain\n",
              "S75_hum_1_Rain.wav         S75            hum      1  Rain"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Appending classification column\n",
        "melody_df['classfcn'] = 'melody'\n",
        "melody_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "G-vWLJoVohKz",
        "outputId": "a7dabc92-8a89-4b67-f38f-1c93facee229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-83189bcd-84d4-4531-8889-ba3de2a4a1c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant</th>\n",
              "      <th>interpretation</th>\n",
              "      <th>number</th>\n",
              "      <th>song</th>\n",
              "      <th>classfcn</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>file_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>S73_hum_1_Rain.wav</th>\n",
              "      <td>S73</td>\n",
              "      <td>hum</td>\n",
              "      <td>1</td>\n",
              "      <td>Rain</td>\n",
              "      <td>melody</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S73_hum_4_Rain.wav</th>\n",
              "      <td>S73</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Rain</td>\n",
              "      <td>melody</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S74_hum_1_Rain.wav</th>\n",
              "      <td>S74</td>\n",
              "      <td>hum</td>\n",
              "      <td>1</td>\n",
              "      <td>Rain</td>\n",
              "      <td>melody</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S74_hum_4_Rain.wav</th>\n",
              "      <td>S74</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Rain</td>\n",
              "      <td>melody</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S75_hum_1_Rain.wav</th>\n",
              "      <td>S75</td>\n",
              "      <td>hum</td>\n",
              "      <td>1</td>\n",
              "      <td>Rain</td>\n",
              "      <td>melody</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83189bcd-84d4-4531-8889-ba3de2a4a1c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83189bcd-84d4-4531-8889-ba3de2a4a1c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83189bcd-84d4-4531-8889-ba3de2a4a1c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   participant interpretation number  song classfcn\n",
              "file_id                                                            \n",
              "S73_hum_1_Rain.wav         S73            hum      1  Rain   melody\n",
              "S73_hum_4_Rain.wav         S73            hum      4  Rain   melody\n",
              "S74_hum_1_Rain.wav         S74            hum      1  Rain   melody\n",
              "S74_hum_4_Rain.wav         S74            hum      4  Rain   melody\n",
              "S75_hum_1_Rain.wav         S75            hum      1  Rain   melody"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading harmonies training and validation data\n",
        "harmonies_sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/harmonies_train/*.wav'\n",
        "files = glob(harmonies_sample_path)\n",
        "len(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJq5-vCNorY6",
        "outputId": "5b65d9e9-9cfa-4bf3-c1f2-38182c151bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1439"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting harmonies info from filenames\n",
        "harmony_table = [] \n",
        "\n",
        "for file in files:\n",
        "  try:\n",
        "    file_name = file.split('/')[-1]\n",
        "    participant_ID = file.split('/')[-1].split('_')[0]\n",
        "    interpretation_type = file.split('/')[-1].split('_')[1]\n",
        "    interpretation_number = file.split('/')[-1].split('_')[2]\n",
        "    song = file.split('/')[-1].split('_')[3].split('.')[0]\n",
        "    harmony_table.append([file_name,participant_ID,interpretation_type,interpretation_number, song])\n",
        "  except:\n",
        "    print(file_name)\n",
        "    \n",
        "harmony_table[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCfbUkc5oxMS",
        "outputId": "5266ec84-4253-42cb-89aa-7c6ed8c8b79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['S72_whistle_1_Panther.wav', 'S72', 'whistle', '1', 'Panther'],\n",
              " ['S73_hum_2_Panther.wav', 'S73', 'hum', '2', 'Panther'],\n",
              " ['S73_hum_4_Panther.wav', 'S73', 'hum', '4', 'Panther'],\n",
              " ['S74_hum_2_Panther.wav', 'S74', 'hum', '2', 'Panther'],\n",
              " ['S74_hum_4_Panther.wav', 'S74', 'hum', '4', 'Panther']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating harmonies dataframe of training files\n",
        "harmony_df = pd.DataFrame(harmony_table,columns=['file_id','participant','interpretation','number','song']).set_index('file_id') \n",
        "harmony_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "A83pIlwro1ii",
        "outputId": "6e447957-0373-466b-a4e0-f73a992b25b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-82106c6c-6a12-4b53-8e0c-0265b03f07ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant</th>\n",
              "      <th>interpretation</th>\n",
              "      <th>number</th>\n",
              "      <th>song</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>file_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>S72_whistle_1_Panther.wav</th>\n",
              "      <td>S72</td>\n",
              "      <td>whistle</td>\n",
              "      <td>1</td>\n",
              "      <td>Panther</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S73_hum_2_Panther.wav</th>\n",
              "      <td>S73</td>\n",
              "      <td>hum</td>\n",
              "      <td>2</td>\n",
              "      <td>Panther</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S73_hum_4_Panther.wav</th>\n",
              "      <td>S73</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Panther</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S74_hum_2_Panther.wav</th>\n",
              "      <td>S74</td>\n",
              "      <td>hum</td>\n",
              "      <td>2</td>\n",
              "      <td>Panther</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S74_hum_4_Panther.wav</th>\n",
              "      <td>S74</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Panther</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82106c6c-6a12-4b53-8e0c-0265b03f07ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82106c6c-6a12-4b53-8e0c-0265b03f07ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82106c6c-6a12-4b53-8e0c-0265b03f07ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                          participant interpretation number     song\n",
              "file_id                                                             \n",
              "S72_whistle_1_Panther.wav         S72        whistle      1  Panther\n",
              "S73_hum_2_Panther.wav             S73            hum      2  Panther\n",
              "S73_hum_4_Panther.wav             S73            hum      4  Panther\n",
              "S74_hum_2_Panther.wav             S74            hum      2  Panther\n",
              "S74_hum_4_Panther.wav             S74            hum      4  Panther"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Appending classification column\n",
        "harmony_df['classfcn'] = 'harmony'\n",
        "harmony_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "zem5PMJBo6oZ",
        "outputId": "12bfdaa7-ddda-4b03-afb4-ed12a4526d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8d45356c-c263-4c70-8471-9c5f9e548602\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant</th>\n",
              "      <th>interpretation</th>\n",
              "      <th>number</th>\n",
              "      <th>song</th>\n",
              "      <th>classfcn</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>file_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>S72_whistle_1_Panther.wav</th>\n",
              "      <td>S72</td>\n",
              "      <td>whistle</td>\n",
              "      <td>1</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S73_hum_2_Panther.wav</th>\n",
              "      <td>S73</td>\n",
              "      <td>hum</td>\n",
              "      <td>2</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S73_hum_4_Panther.wav</th>\n",
              "      <td>S73</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S74_hum_2_Panther.wav</th>\n",
              "      <td>S74</td>\n",
              "      <td>hum</td>\n",
              "      <td>2</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S74_hum_4_Panther.wav</th>\n",
              "      <td>S74</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d45356c-c263-4c70-8471-9c5f9e548602')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d45356c-c263-4c70-8471-9c5f9e548602 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d45356c-c263-4c70-8471-9c5f9e548602');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                          participant interpretation number     song classfcn\n",
              "file_id                                                                      \n",
              "S72_whistle_1_Panther.wav         S72        whistle      1  Panther  harmony\n",
              "S73_hum_2_Panther.wav             S73            hum      2  Panther  harmony\n",
              "S73_hum_4_Panther.wav             S73            hum      4  Panther  harmony\n",
              "S74_hum_2_Panther.wav             S74            hum      2  Panther  harmony\n",
              "S74_hum_4_Panther.wav             S74            hum      4  Panther  harmony"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With classification assigned, all audio files are transerred to a single folder labelled \"combined_train\". Associated dataframes are concatenated row-wise to form a single dataframe \"combined_df\"."
      ],
      "metadata": {
        "id": "djBfo9jnpGo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating dataframes\n",
        "frames = [melody_df, harmony_df]\n",
        "combined_df = pd.concat(frames)\n",
        "\n",
        "print(\"Combined dataframe has shape:\", combined_df.shape)\n",
        "print(\"\\nThe confluence of concatenation is:\\n\")\n",
        "combined_df[1429:1439]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "z9UgWddQpL5Z",
        "outputId": "17e77ec8-c3af-428d-c296-ca1fd423e8bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataframe has shape: (2871, 5)\n",
            "\n",
            "The confluence of concatenation is:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9c0d676f-ed8a-42cf-8b39-ed9bcde13cf0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant</th>\n",
              "      <th>interpretation</th>\n",
              "      <th>number</th>\n",
              "      <th>song</th>\n",
              "      <th>classfcn</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>file_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>S71_hum_4_Rain.wav</th>\n",
              "      <td>S71</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Rain</td>\n",
              "      <td>melody</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S72_hum_1_Rain.wav</th>\n",
              "      <td>S72</td>\n",
              "      <td>hum</td>\n",
              "      <td>1</td>\n",
              "      <td>Rain</td>\n",
              "      <td>melody</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S72_whistle_2_Rain.wav</th>\n",
              "      <td>S72</td>\n",
              "      <td>whistle</td>\n",
              "      <td>2</td>\n",
              "      <td>Rain</td>\n",
              "      <td>melody</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S72_whistle_1_Panther.wav</th>\n",
              "      <td>S72</td>\n",
              "      <td>whistle</td>\n",
              "      <td>1</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S73_hum_2_Panther.wav</th>\n",
              "      <td>S73</td>\n",
              "      <td>hum</td>\n",
              "      <td>2</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S73_hum_4_Panther.wav</th>\n",
              "      <td>S73</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S74_hum_2_Panther.wav</th>\n",
              "      <td>S74</td>\n",
              "      <td>hum</td>\n",
              "      <td>2</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S74_hum_4_Panther.wav</th>\n",
              "      <td>S74</td>\n",
              "      <td>hum</td>\n",
              "      <td>4</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S75_hum_2_Panther.wav</th>\n",
              "      <td>S75</td>\n",
              "      <td>hum</td>\n",
              "      <td>2</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S75_whistle_1_Panther.wav</th>\n",
              "      <td>S75</td>\n",
              "      <td>whistle</td>\n",
              "      <td>1</td>\n",
              "      <td>Panther</td>\n",
              "      <td>harmony</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c0d676f-ed8a-42cf-8b39-ed9bcde13cf0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c0d676f-ed8a-42cf-8b39-ed9bcde13cf0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c0d676f-ed8a-42cf-8b39-ed9bcde13cf0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                          participant interpretation number     song classfcn\n",
              "file_id                                                                      \n",
              "S71_hum_4_Rain.wav                S71            hum      4     Rain   melody\n",
              "S72_hum_1_Rain.wav                S72            hum      1     Rain   melody\n",
              "S72_whistle_2_Rain.wav            S72        whistle      2     Rain   melody\n",
              "S72_whistle_1_Panther.wav         S72        whistle      1  Panther  harmony\n",
              "S73_hum_2_Panther.wav             S73            hum      2  Panther  harmony\n",
              "S73_hum_4_Panther.wav             S73            hum      4  Panther  harmony\n",
              "S74_hum_2_Panther.wav             S74            hum      2  Panther  harmony\n",
              "S74_hum_4_Panther.wav             S74            hum      4  Panther  harmony\n",
              "S75_hum_2_Panther.wav             S75            hum      2  Panther  harmony\n",
              "S75_whistle_1_Panther.wav         S75        whistle      1  Panther  harmony"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to repeated persistent kernel failure to execute after many, many hours (classification in dataframe does not affect actual audio files), it is decided to change approach to the task by working directly with the folder of combined files and effecting classification at the level of the function \"getXy\" using the statement<br> \n",
        "\n",
        "``yi = labels_file.loc[fileID]['song'] == ['Potter', 'Rain', 'Mamma', 'Frozen']``<br> \n",
        "\n",
        "instead of the above separated melodies and harmonies files approach."
      ],
      "metadata": {
        "id": "7u8cEx9cR7nK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resetting path for combined data\n",
        "combined_sample_path = '/content/drive/MyDrive/Data2/MLEndHW2/combined_train/*.wav'\n",
        "files = glob(combined_sample_path)\n",
        "len(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMo0UTCpwOEo",
        "outputId": "5a5f840d-4d5b-4594-e9ed-d658c91c6608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2870"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting files\n",
        "for file in files:\n",
        "  file.split('/')[-1]\n",
        "\n",
        "print(\"File splitting completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oCIGcRgbzgm",
        "outputId": "a2f58b09-5712-4574-e260-926759eae203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File splitting completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting combined info from filenames\n",
        "combined_table = [] \n",
        "\n",
        "for file in files:\n",
        "  try:\n",
        "    file_name = file.split('/')[-1]\n",
        "    participant_ID = file.split('/')[-1].split('_')[0]\n",
        "    interpretation_type = file.split('/')[-1].split('_')[1]\n",
        "    interpretation_number = file.split('/')[-1].split('_')[2]\n",
        "    song = file.split('/')[-1].split('_')[3].split('.')[0]\n",
        "    combined_table.append([file_name,participant_ID,interpretation_type,interpretation_number, song])\n",
        "  except:\n",
        "    print(file_name)\n",
        "    \n",
        "combined_table[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT6sBb_e3j2v",
        "outputId": "f8e27519-66ff-41eb-e69c-5d4cdd1dee4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['S78_hum_2_Mamma.wav', 'S78', 'hum', '2', 'Mamma'],\n",
              " ['S78_whistle_2_Mamma.wav', 'S78', 'whistle', '2', 'Mamma'],\n",
              " ['S79_hum_1_[mamma].wav', 'S79', 'hum', '1', '[mamma]'],\n",
              " ['S79_hum_3_[Mamma].wav', 'S79', 'hum', '3', '[Mamma]'],\n",
              " ['S80_hum_2_Mamma.wav', 'S80', 'hum', '2', 'Mamma']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating combined dataframe of training files\n",
        "combined_df = pd.DataFrame(combined_table,columns=['file_id','participant','interpretation','number','song']).set_index('file_id') \n",
        "combined_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "p1GHReMo4Blv",
        "outputId": "3fa8c797-4571-401c-9018-5463d42fab71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d08282c4-a9c6-429f-b9ab-59bd27f6dc07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant</th>\n",
              "      <th>interpretation</th>\n",
              "      <th>number</th>\n",
              "      <th>song</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>file_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>S78_hum_2_Mamma.wav</th>\n",
              "      <td>S78</td>\n",
              "      <td>hum</td>\n",
              "      <td>2</td>\n",
              "      <td>Mamma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S78_whistle_2_Mamma.wav</th>\n",
              "      <td>S78</td>\n",
              "      <td>whistle</td>\n",
              "      <td>2</td>\n",
              "      <td>Mamma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S79_hum_1_[mamma].wav</th>\n",
              "      <td>S79</td>\n",
              "      <td>hum</td>\n",
              "      <td>1</td>\n",
              "      <td>[mamma]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S79_hum_3_[Mamma].wav</th>\n",
              "      <td>S79</td>\n",
              "      <td>hum</td>\n",
              "      <td>3</td>\n",
              "      <td>[Mamma]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S80_hum_2_Mamma.wav</th>\n",
              "      <td>S80</td>\n",
              "      <td>hum</td>\n",
              "      <td>2</td>\n",
              "      <td>Mamma</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d08282c4-a9c6-429f-b9ab-59bd27f6dc07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d08282c4-a9c6-429f-b9ab-59bd27f6dc07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d08282c4-a9c6-429f-b9ab-59bd27f6dc07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                        participant interpretation number     song\n",
              "file_id                                                           \n",
              "S78_hum_2_Mamma.wav             S78            hum      2    Mamma\n",
              "S78_whistle_2_Mamma.wav         S78        whistle      2    Mamma\n",
              "S79_hum_1_[mamma].wav           S79            hum      1  [mamma]\n",
              "S79_hum_3_[Mamma].wav           S79            hum      3  [Mamma]\n",
              "S80_hum_2_Mamma.wav             S80            hum      2    Mamma"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 4: Transformation Stage**<br> \n",
        "In this analysis, 4 features are extracted from each audio file and assembled in an array described by a dataframe. These 4 features, used as input for the task model, are:<br> \n",
        "\n",
        "1.   Power.\n",
        "2.   Pitch mean.\n",
        "3.   Pitch standard deviation.\n",
        "4.   Fraction of voiced region.\n",
        "\n",
        "The extraction of these features requires first a Fourier transformation of the waveform into discrete frequencies over the range of the segment.<br> \n",
        "**Power** is \"the sum of the absolute squares of a signal's time-domain samples divided by the signal length, or, equivalently, the square of its root mean square level\"$^4$. From general knowledge that power is energy  divided by time taken, the power of a sound signal is basically its loudness, i.e. how quickly the signal's energy is delivered.<br> \n",
        "**Pitch mean**: Pitch is the property of sound that enables its judgement as low or high (and anywhere in between) on the musical scale, and is measured as frequency (in Hz). Pitch mean is the mean frequency in a segment.<br> \n",
        "**Pitch standard deviation** is the _spread_ of the main frequencies of the audio segment.<br> \n",
        "**Fraction of voiced region** is the proportion or ratio of an audio segment that actually has sound/signal output to total audio segment time. Its converse is silent regions or regions with no signal output, i.e. silence or just noise. The periodicity of this property of sound may contain discernible information is thus used as a feature of audio analysis.<br> \n",
        "\n",
        "#### **Section 4.1: Feature Extraction**\n",
        "The next step defines a function for determining the pitch of an audio segments:"
      ],
      "metadata": {
        "id": "cUHkLZVdSqnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getPitch(x,fs,winLen=0.02):\n",
        "  p = winLen*fs\n",
        "  frame_length = int(2**int(p-1).bit_length())\n",
        "  hop_length = frame_length//2\n",
        "  f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs, frame_length=frame_length,hop_length=hop_length)\n",
        "  return f0,voiced_flag\n",
        "\n",
        "print(\"Pitch function created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAb-IX5_Dt6S",
        "outputId": "a364a352-9be3-4d5f-811d-2beab68fb2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pitch function created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getXy(files,labels_file, scale_audio=False, onlySingleDigit=False):\n",
        "  X,y =[],[]\n",
        "  for file in tqdm(files):\n",
        "    fileID = file.split('/')[-1]\n",
        "    file_name = file.split('/')[-1]\n",
        "    yi = labels_file.loc[fileID]['song'] == 'Potter', 'Rain', 'Mamma', 'Frozen' # this establishes the classification\n",
        "\n",
        "    fs = None # fs would default to 22050\n",
        "    x, fs = librosa.load(file,sr=fs)\n",
        "    if scale_audio: x = x/np.max(np.abs(x))\n",
        "    f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n",
        "      \n",
        "    power = np.sum(x**2)/len(x)\n",
        "    pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "    pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "    voiced_fr = np.mean(voiced_flag)\n",
        "\n",
        "    xi = [power,pitch_mean,pitch_std,voiced_fr]\n",
        "    X.append(xi)\n",
        "    y.append(yi)\n",
        "\n",
        "  return np.array(X),np.array(y)\n",
        "\n",
        "print(\"Feature extraction function created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNKejmwDDz6Q",
        "outputId": "072b3922-d8bc-41d2-c33d-85335f16f147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction function created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 5: Modelling**<br> \n",
        "\n",
        "Classification is set such that 'Potter', 'Rain', 'Mamma', and 'Frozen' evaluate to 1 (True) and StarWars, Panther, Hakuna, and Showman to 0 (False) during definition of the above function.<br> \n",
        "\n",
        "A numpy predictor array `X` and a binary label vector `y`of actual audio data are obtained next and their shapes output as follows:"
      ],
      "metadata": {
        "id": "a2Uy1cUwE4jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating predictor array and label vector\n",
        "X,y = getXy(files, labels_file=combined_df, scale_audio=True, onlySingleDigit=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6N6bsZpD9PS",
        "outputId": "99ab45bc-1756-41fe-a48f-11af7f17fca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 2870/2870 [2:46:03<00:00,  3.47s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Outputting shapes and arrays\n",
        "print('The shape of X is', X.shape) \n",
        "print('The shape of y is', y.shape)\n",
        "print('The features matrix is', X)\n",
        "print('The labels vector is', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQP2RgWuQVG8",
        "outputId": "12aeeba6-ca70-40e9-f54c-d71a8a8af249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of X is (2870, 4)\n",
            "The shape of y is (2870, 4)\n",
            "The features matrix is [[3.29445416e-02 1.63847849e+02 2.33039344e+01 6.05075337e-01]\n",
            " [1.69751481e-02 4.10724167e+02 2.57669233e+01 5.53311793e-01]\n",
            " [5.38656931e-02 3.27666777e+02 4.29379334e+01 6.60246533e-01]\n",
            " ...\n",
            " [2.96142031e-02 2.13179964e+02 5.90148448e+01 8.71062271e-01]\n",
            " [3.11814236e-02 3.94748263e+02 2.79719036e+01 7.72241993e-01]\n",
            " [3.54416091e-02 1.44451579e+02 2.77358846e+01 7.48224152e-01]]\n",
            "The labels vector is [['False' 'Rain' 'Mamma' 'Frozen']\n",
            " ['False' 'Rain' 'Mamma' 'Frozen']\n",
            " ['False' 'Rain' 'Mamma' 'Frozen']\n",
            " ...\n",
            " ['False' 'Rain' 'Mamma' 'Frozen']\n",
            " ['False' 'Rain' 'Mamma' 'Frozen']\n",
            " ['False' 'Rain' 'Mamma' 'Frozen']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for class imbalance\n",
        "print('The number of melodic recordings in the training dataset is', np.count_nonzero(y))\n",
        "print('The number of harmonic recordings in the training dataset is', y.size - np.count_nonzero(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI8NNmbyTsCY",
        "outputId": "6d3c851d-cf79-4cab-b706-6e10b15b7248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of melodic recordings in the training dataset is 11480\n",
            "The number of harmonic recordings in the training dataset is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is decided not to normalise the data prior to inputting the model, the judgement being that it would be better for model training and provide better test and deployment accuracy with less likelihood of overfitting.<br>"
      ],
      "metadata": {
        "id": "835Aok8_WzBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 6: Methodology**<br> \n",
        "\n",
        "#### **Section 6.1: Model Fitting, Training and Validation**<br> \n",
        "\n",
        "In the next few steps the data is split 75% and 25% respectively for training and validation, and a simple neural network model created:"
      ],
      "metadata": {
        "id": "_zGSP_kxGPLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.25)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W-qPVu1WhQI",
        "outputId": "83492945-dd80-4d77-f070-4fa20f599e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2152, 4), (718, 4), (2152, 4), (718, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following a fairly proportional review of the literature the model of choice for this notebook is a simple neural network (NN), as this method is widely employed with good success for audio analysis. With the nature of the data (i.e timeseries/digital signal processing, 4 features, 2871 items) and the goal of analysis in mind (i.e. distinguish between melodies and harmonies = binary classification), it is decided to build a sequential NN with an input layer consisting of 12 perceptrons, with 3 hidden layers of 24:12:6 perceptrons, and an output layer of 1 perceptron. <br> \n",
        "\n",
        "The following model design is created:<br> \n",
        "\n",
        "**Sequential** : Defines a sequance of layers in the neural network.\n",
        "\n",
        "**Flatten** : Turns images into a 1 dimensional array.\n",
        "\n",
        "**Dense** : Adds a layer of neurons.\n",
        "\n",
        "**Activation function** : Nonlinearities that define node output. Each layer of neurons needs an activation function to tell them what to do.\n",
        "\n",
        "**Relu** : Rectified Linear Unit, a ramp function comprising the positive part of the argument of an activation function - effectively means \"if X>0 return X, else return 0\", hence it only passes values 0 or greater to the next layer in the model. It is less computationally intensive, and of good utility in hidden layers.\n",
        "\n",
        "**Sigmoid** :  One of many last activation functions of a neural network, it is nonlinear, maps logistic or multinomial regression output to probabilities between 0 and 1, and one of recommended last activation functions for binary classification.\n",
        "\n",
        "**Optimizer**: In this case, using the RMSprop optimization algorithm is preferable to stochastic gradient descent (SGD), because RMSprop automates learning-rate tuning.\n",
        "\n",
        "**Loss function**: BinaryCrossentropy is chosen as loss function to maximise quantification of the difference between the two probability distributions of melody or harmony."
      ],
      "metadata": {
        "id": "s9Z1T_3YYDhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing library\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# Defining callback function\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.95):\n",
        "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "print(\"Callback function defined.\")"
      ],
      "metadata": {
        "id": "kYN9hkLG5WUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba36e5b3-45e2-4c60-e5a6-58c4468e950a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Callback function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passing np array data into tf Dataset\n",
        "training_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "validation_data = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "print(\"Training and validation data passed, ready for loading.\")"
      ],
      "metadata": {
        "id": "gpR4RveE5bMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0a75b2-9f95-4ca2-8371-d3cf2af5c248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and validation data passed, ready for loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffling and batching data\n",
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 50\n",
        "\n",
        "training_data = training_data.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "validation_data = validation_data.batch(BATCH_SIZE)\n",
        "\n",
        "print(\"Dataset shuffled 50 at a time, and to transit in batches of 32.\")"
      ],
      "metadata": {
        "id": "Earzjza-5fiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba3e479-a090-455f-86ea-b5581b1b146c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shuffled 50 at a time, and to transit in batches of 32.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building NN model architecture\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(12, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(24, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(12, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(6, activation='relu'), \n",
        "                                    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "print(\"Simple NN model building completed.\")"
      ],
      "metadata": {
        "id": "OyAQLxeJ5kGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba972bd-0542-4326-adeb-0f96549c1c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple NN model building completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining NN compiler\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Simple NN model compiler defined.\")"
      ],
      "metadata": {
        "id": "-GrFfN7X5nwa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c3d76d-5d38-48ed-9b10-89f7d81236e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple NN model compiler defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "model.fit(training_data, epochs=30, callbacks=[callbacks])\n",
        "print(\"Model training completed.\")"
      ],
      "metadata": {
        "id": "4RCClduT8nO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validating the model\n",
        "model.evaluate(validation_data)\n",
        "print(\"Model validation completed.\")"
      ],
      "metadata": {
        "id": "fAJ2qOWG5u_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Section 6.2: Testing**<br> \n",
        "The following few steps are meant to test the model to determine its performance in conditions of real deployment."
      ],
      "metadata": {
        "id": "mnGSQi0t50Ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading combined test data\n",
        "test_path = '/content/drive/MyDrive/Data2/MLEndHW2/combined_test/*.wav'\n",
        "test_files = glob(test_path)\n",
        "len(test_files)"
      ],
      "metadata": {
        "id": "fOcRNt4S55gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting files\n",
        "for file in files:\n",
        "  file.split('/')[-1]\n",
        "\n",
        "print(\"File splitting completed.\")"
      ],
      "metadata": {
        "id": "R0jBeMiX58uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting combined test info from filenames\n",
        "test_table = [] \n",
        "\n",
        "for file in files:\n",
        "  try:\n",
        "    file_name = file.split('/')[-1]\n",
        "    participant_ID = file.split('/')[-1].split('_')[0]\n",
        "    interpretation_type = file.split('/')[-1].split('_')[1]\n",
        "    interpretation_number = file.split('/')[-1].split('_')[2]\n",
        "    song = file.split('/')[-1].split('_')[3].split('.')[0]\n",
        "    test_table.append([file_name,participant_ID,interpretation_type,interpretation_number, song])\n",
        "  except:\n",
        "    print(file_name)\n",
        "    \n",
        "test_table[:5]"
      ],
      "metadata": {
        "id": "Y2YCzm-n6C8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataframe of test files\n",
        "test_df = pd.DataFrame(test_table,columns=['file_id','participant','interpretation','number','song']).set_index('file_id') \n",
        "test_df.head(5)"
      ],
      "metadata": {
        "id": "Rqi9_Dk56NFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating test arrays\n",
        "X1_test,y1_test = getXy(test_files, labels_file=test_df, scale_audio=True, onlySingleDigit=True)"
      ],
      "metadata": {
        "id": "bHxAKqZG6R0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outputting test shapes and arrays\n",
        "print('The shape of X1_test is', X1_test.shape) \n",
        "print('The shape of y1_test is', y1_test.shape)\n",
        "print('The features matrix is', X1_test)\n",
        "print('The labels vector is', y1_test)"
      ],
      "metadata": {
        "id": "FoNg0Btt6VTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for class imbalance\n",
        "print('The number of melodic recordings in the testing dataset is', np.count_nonzero(y1_test))\n",
        "print('The number of harmonic recordings in the testing dataset is', y1_test.size - np.count_nonzero(y1_test))"
      ],
      "metadata": {
        "id": "092dKCdm6bir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passing test array data into tf Dataset\n",
        "testing_data = tf.data.Dataset.from_tensor_slices((X1_test, y1_test))\n",
        "print(\"Test data passed, ready for loading.\")"
      ],
      "metadata": {
        "id": "u7Dfkv6A6ga6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_classifications = model.predict(testing_data)\n",
        "print(test_classifications[5:35])\n",
        "print(y1_test[5:35])"
      ],
      "metadata": {
        "id": "a_vZRUV76wua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 7: Dataset**<br> \n",
        "The dataset for this analysis is the MLEnd Hums and Whistles public dataset version 0. It consists of participant-submitted 15-second humming and whistling recordings of fragments of 8 different movie songs. Each participant submitted 2 humming and 2 whistling renditions per song (32 per participant), along with their demographic data. Demographic data is currently unavailable for this task.<br> \n",
        "\n",
        "With 210 participants there are 210 x 4 x 8 = 6720 audio files, anonymised with sample numbers, e.g. S12."
      ],
      "metadata": {
        "id": "RuT-Ji6EHWEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 8: Results**<br> \n",
        "The results obtained with the dataset and pipeline above can be summarised as:<br> \n",
        "\n",
        "**i. Training Accuracy** "
      ],
      "metadata": {
        "id": "NQV0VO0vHkZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ii. Validation Accuracy**"
      ],
      "metadata": {
        "id": "cXjJvzb7HrJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**iii. Support Vectors**"
      ],
      "metadata": {
        "id": "_znSU_WbHziz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**iv. Test Accuracy**"
      ],
      "metadata": {
        "id": "eS9OdnQmH-N6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <center>**References**</center> \n",
        "1. https://www.masterclass.com/articles/melody-vs-harmony-similarities-and-differences-with-musical-examples#consonance-and-dissonance\n",
        "\n",
        "2. Mikio Tohyama, *Waveform Analysis of Sound: 3 (Mathematics for Industry)*, 1$^{st}$ edn (Springer, 2015), p. 90.\n",
        "\n",
        "3. https://en.wikipedia.org/wiki/Harmony\n",
        "\n",
        "4. https://www.kdnuggets.com/2020/02/audio-data-analysis-deep-learning-python-part-1.html"
      ],
      "metadata": {
        "id": "gdeJS5TBYYn2"
      }
    }
  ]
}